(.venv) PS D:\DDOS PSO CNN LSTM> python ddos_detector_custom.py
Using CPU
======================================================================
DDoS Detection System - PSO Optimized CNN-LSTM Hybrid Model
PSO + CNN + LSTM Hybrid Approach for Network Security
======================================================================

Loading data...
Looking for CSV files in: D:\DDOS PSO CNN LSTM\CSV
Loaded DrDoS_DNS.csv with 600 rows
Loaded DrDoS_LDAP.csv with 600 rows
Loaded DrDoS_MSSQL.csv with 600 rows
Loaded DrDoS_NetBIOS.csv with 600 rows
Loaded DrDoS_NTP.csv with 600 rows
Loaded DrDoS_SSDP.csv with 600 rows
Loaded DrDoS_UDP.csv with 600 rows
Loaded Syn.csv with 600 rows
Loaded TFTP.csv with 600 rows
Loaded UDPLag.csv with 600 rows
Warning: Data contains NaN values
Warning: Data contains infinite values

Creating sequences...
Sequence shapes - X: (5990, 10, 82), y: (5990,)

Splitting data...

Training PSO + CNN + LSTM hybrid model...

Training PSO + CNN + LSTM Hybrid Model
Training shapes - X_train: (3354, 10, 82), y_train: (3354,)
Validation shapes - X_val: (839, 10, 82), y_val: (839,)

Starting PSO optimization for CNN-LSTM hybrid model...
PSO + CNN + LSTM Hybridization Process:
- PSO searches for optimal hyperparameters
- CNN extracts spatial features from network traffic
- LSTM captures temporal dependencies in sequences
- Hybrid model combines strengths of all three approaches
No constraints given.
Iteration 1: Fitness = 0.1224
Iteration 2: Fitness = 0.4172
Iteration 3: Fitness = 0.2153
Iteration 4: Fitness = 0.1572
Iteration 5: Fitness = 0.1248
Iteration 6: Fitness = 0.3887
Iteration 7: Fitness = 0.3389
Iteration 8: Fitness = 0.2121
Iteration 9: Fitness = 0.4451
Iteration 10: Fitness = 0.1079
Iteration 11: Fitness = 0.1297
Iteration 12: Fitness = 0.1832
Iteration 13: Fitness = 0.2357
Iteration 14: Fitness = 0.2190
Iteration 15: Fitness = 0.1655
Iteration 16: Fitness = 0.4544
Iteration 17: Fitness = 0.1835
Iteration 18: Fitness = 0.2330
Iteration 19: Fitness = 0.2933
Iteration 20: Fitness = 0.1986
Best after iteration 1: [8.29647976e+01 2.38499829e+02 5.18223205e+01 3.79500806e+01
 1.18090916e-01 3.32077027e-03] 0.10791613161563873
Iteration 21: Fitness = 0.1570
Iteration 22: Fitness = 0.1723
Iteration 23: Fitness = 0.2142
Iteration 24: Fitness = 0.1988
Iteration 25: Fitness = 0.1161
Iteration 26: Fitness = 0.2681
Iteration 27: Fitness = 0.2395
Iteration 28: Fitness = 0.2594
Iteration 29: Fitness = 0.2818
Iteration 30: Fitness = 0.2852
Best after iteration 2: [8.29647976e+01 2.38499829e+02 5.18223205e+01 3.79500806e+01
 1.18090916e-01 3.32077027e-03] 0.10791613161563873
Iteration 31: Fitness = 0.1190
Iteration 32: Fitness = 0.1855
Iteration 33: Fitness = 0.1792
Iteration 34: Fitness = 0.1266
Iteration 35: Fitness = 0.1491
Iteration 36: Fitness = 0.2241
Iteration 37: Fitness = 0.3268
Iteration 38: Fitness = 0.1830
Iteration 39: Fitness = 0.4894
Iteration 40: Fitness = 0.5546
Best after iteration 3: [8.29647976e+01 2.38499829e+02 5.18223205e+01 3.79500806e+01
 1.18090916e-01 3.32077027e-03] 0.10791613161563873
Iteration 41: Fitness = 0.2564
Iteration 42: Fitness = 0.1199
Iteration 43: Fitness = 0.1677
Iteration 44: Fitness = 0.4831
Iteration 45: Fitness = 0.2082
Iteration 46: Fitness = 0.2193
Iteration 47: Fitness = 0.1896
Iteration 48: Fitness = 0.3709
Iteration 49: Fitness = 0.2609
Iteration 50: Fitness = 0.1917
Best after iteration 4: [8.29647976e+01 2.38499829e+02 5.18223205e+01 3.79500806e+01
 1.18090916e-01 3.32077027e-03] 0.10791613161563873
Iteration 51: Fitness = 0.3482
Iteration 52: Fitness = 0.1027
New best for swarm at iteration 5: [6.24852814e+01 2.52362185e+02 3.20000000e+01 6.83204170e+01
 1.96787082e-01 2.90314276e-03] 0.1026606634259224
Iteration 53: Fitness = 0.1689
Iteration 54: Fitness = 0.3557
Iteration 55: Fitness = 0.1341
Iteration 56: Fitness = 0.2772
Iteration 57: Fitness = 0.2596
Iteration 58: Fitness = 0.2072
Iteration 59: Fitness = 0.2390
Iteration 60: Fitness = 0.1989
Best after iteration 5: [6.24852814e+01 2.52362185e+02 3.20000000e+01 6.83204170e+01
 1.96787082e-01 2.90314276e-03] 0.1026606634259224
Iteration 61: Fitness = 0.2452
Iteration 62: Fitness = 0.3050
Iteration 63: Fitness = 0.2540
Iteration 64: Fitness = 0.3436
Iteration 65: Fitness = 0.2644
Iteration 66: Fitness = 0.1926
Iteration 67: Fitness = 0.1363
Iteration 68: Fitness = 0.2064
Iteration 69: Fitness = 0.1809
Iteration 70: Fitness = 0.1597
Best after iteration 6: [6.24852814e+01 2.52362185e+02 3.20000000e+01 6.83204170e+01
 1.96787082e-01 2.90314276e-03] 0.1026606634259224
Iteration 71: Fitness = 0.1715
Iteration 72: Fitness = 0.2790
Iteration 73: Fitness = 0.0973
New best for swarm at iteration 7: [6.70083484e+01 2.55654048e+02 4.25044026e+01 6.38647957e+01
 1.95189325e-01 2.62210561e-03] 0.0973149910569191
Iteration 74: Fitness = 0.2968
Iteration 75: Fitness = 0.2383
Iteration 76: Fitness = 0.1598
Iteration 77: Fitness = 0.3332
Iteration 78: Fitness = 0.3078
Iteration 79: Fitness = 0.1715
Iteration 80: Fitness = 0.1566
Best after iteration 7: [6.70083484e+01 2.55654048e+02 4.25044026e+01 6.38647957e+01
 1.95189325e-01 2.62210561e-03] 0.0973149910569191
Iteration 81: Fitness = 0.2839
Iteration 82: Fitness = 0.1744
Iteration 83: Fitness = 0.1328
Iteration 84: Fitness = 0.0989
Iteration 85: Fitness = 0.1154
Iteration 86: Fitness = 0.1640
Iteration 87: Fitness = 0.4594
Iteration 88: Fitness = 0.5366
Iteration 89: Fitness = 0.2190
Iteration 90: Fitness = 0.2315
Best after iteration 8: [6.70083484e+01 2.55654048e+02 4.25044026e+01 6.38647957e+01
 1.95189325e-01 2.62210561e-03] 0.0973149910569191
Iteration 91: Fitness = 0.0952
New best for swarm at iteration 9: [6.33607288e+01 2.41524000e+02 6.95124654e+01 5.49268183e+01
 1.59556711e-01 2.72707171e-03] 0.09519203007221222
Iteration 92: Fitness = 0.1160
Iteration 93: Fitness = 0.2371
Iteration 94: Fitness = 0.3965
Iteration 95: Fitness = 0.0893
New best for swarm at iteration 9: [6.61653822e+01 2.22157963e+02 8.03016564e+01 7.01422674e+01
 3.51506718e-01 1.05830520e-03] 0.08932340890169144
Iteration 96: Fitness = 0.1423
Iteration 97: Fitness = 0.2566
Iteration 98: Fitness = 0.4712
Iteration 99: Fitness = 0.2199
Iteration 100: Fitness = 0.1391
Best after iteration 9: [6.61653822e+01 2.22157963e+02 8.03016564e+01 7.01422674e+01
 3.51506718e-01 1.05830520e-03] 0.08932340890169144
Iteration 101: Fitness = 0.1135
Iteration 102: Fitness = 0.1072
Iteration 103: Fitness = 0.0943
Iteration 104: Fitness = 0.1762
Iteration 105: Fitness = 0.2524
Iteration 106: Fitness = 0.1393
Iteration 107: Fitness = 0.1244
Iteration 108: Fitness = 0.1433
Iteration 109: Fitness = 0.1496
Iteration 110: Fitness = 0.2035
Best after iteration 10: [6.61653822e+01 2.22157963e+02 8.03016564e+01 7.01422674e+01
 3.51506718e-01 1.05830520e-03] 0.08932340890169144
Iteration 111: Fitness = 0.3194
Iteration 112: Fitness = 0.1188
Iteration 113: Fitness = 0.0955
Iteration 114: Fitness = 0.2800
Iteration 115: Fitness = 0.2102
Iteration 116: Fitness = 0.1588
Iteration 117: Fitness = 0.2139
Iteration 118: Fitness = 0.1708
Iteration 119: Fitness = 0.2148
Iteration 120: Fitness = 0.2119
Best after iteration 11: [6.61653822e+01 2.22157963e+02 8.03016564e+01 7.01422674e+01
 3.51506718e-01 1.05830520e-03] 0.08932340890169144
Iteration 121: Fitness = 0.4118
Iteration 122: Fitness = 0.2327
Iteration 123: Fitness = 0.1273
Iteration 124: Fitness = 0.1017
Iteration 125: Fitness = 0.2767
Iteration 126: Fitness = 0.1445
Iteration 127: Fitness = 0.1530
Iteration 128: Fitness = 0.1636
Iteration 129: Fitness = 0.1574
Iteration 130: Fitness = 0.1979
Best after iteration 12: [6.61653822e+01 2.22157963e+02 8.03016564e+01 7.01422674e+01
 3.51506718e-01 1.05830520e-03] 0.08932340890169144
Iteration 131: Fitness = 0.1290
Iteration 132: Fitness = 0.1803
Iteration 133: Fitness = 0.2670
Iteration 134: Fitness = 0.1207
Iteration 135: Fitness = 0.2411
Iteration 136: Fitness = 0.1636
Iteration 137: Fitness = 0.1822
Iteration 138: Fitness = 0.2902
Iteration 139: Fitness = 0.1196
Iteration 140: Fitness = 0.3193
Best after iteration 13: [6.61653822e+01 2.22157963e+02 8.03016564e+01 7.01422674e+01
 3.51506718e-01 1.05830520e-03] 0.08932340890169144
Iteration 141: Fitness = 0.1442
Iteration 142: Fitness = 0.1582
Iteration 143: Fitness = 0.1095
Iteration 144: Fitness = 0.2929
Iteration 145: Fitness = 0.0997
Iteration 146: Fitness = 0.1480
Iteration 147: Fitness = 0.0994
Iteration 148: Fitness = 0.1983
Iteration 149: Fitness = 0.1933
Iteration 150: Fitness = 0.1129
Best after iteration 14: [6.61653822e+01 2.22157963e+02 8.03016564e+01 7.01422674e+01
 3.51506718e-01 1.05830520e-03] 0.08932340890169144
Iteration 151: Fitness = 0.2537
Iteration 152: Fitness = 0.4521
Iteration 153: Fitness = 0.3560
Iteration 154: Fitness = 0.0923
Iteration 155: Fitness = 0.1291
Iteration 156: Fitness = 0.2385
Iteration 157: Fitness = 0.1086
Iteration 158: Fitness = 0.1371
Iteration 159: Fitness = 0.1189
Iteration 160: Fitness = 0.3370
Best after iteration 15: [6.61653822e+01 2.22157963e+02 8.03016564e+01 7.01422674e+01
 3.51506718e-01 1.05830520e-03] 0.08932340890169144
Stopping search: maximum iterations reached --> 15

PSO + CNN + LSTM optimized parameters (Best Score: 0.0893):
conv1_filters: 66
conv2_filters: 222
lstm_units: 80
dense_units: 70
dropout_rate: 0.3515067181024462
learning_rate: 0.0010583051999192164
Building PSO + CNN + LSTM Hybrid Model Architecture:
============================================================
1. CNN Layers for spatial feature extraction
2. LSTM Layers for temporal pattern recognition
3. PSO-optimized hyperparameters for optimal performance
============================================================

PSO + CNN + LSTM Hybrid Model Architecture:
Model: "sequential_160"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv1d_320 (Conv1D)         (None, 10, 66)            16302

 batch_normalization_320 (Ba  (None, 10, 66)           264
 tchNormalization)

 max_pooling1d_160 (MaxPooli  (None, 5, 66)            0
 ng1D)

 conv1d_321 (Conv1D)         (None, 5, 222)            44178

 batch_normalization_321 (Ba  (None, 5, 222)           888
 tchNormalization)

 dropout_640 (Dropout)       (None, 5, 222)            0

 lstm_320 (LSTM)                          96960

 dropout_641 (Dropout)       (None, 5, 80)             0

 lstm_321 (LSTM)             (None, 40)                19360

 dropout_642 (Dropout)       (None, 40)                0

 dense_320 (Dense)           (None, 70)                2870

 dropout_643 (Dropout)       (None, 70)                0

 dense_321 (Dense)           (None, 11)                781

=================================================================
Total params: 181,603
Trainable params: 181,027
Non-trainable params: 576
_________________________________________________________________

Training the PSO-optimized CNN-LSTM hybrid model...
Epoch 1/100
53/53 [==============================] - 3s 19ms/step - loss: 1.3681 - accuracy: 0.6240 - val_loss: 0.8495 - val_accuracy: 0.7402 - lr: 0.0011
Epoch 2/100
53/53 [==============================] - 1s 11ms/step - loss: 0.4433 - accuracy: 0.8494 - val_loss: 0.4214 - val_accuracy: 0.8021 - lr: 0.0011
Epoch 3/100
53/53 [==============================] - 1s 11ms/step - loss: 0.3436 - accuracy: 0.8623 - val_loss: 0.3899 - val_accuracy: 0.8212 - lr: 0.0011
Epoch 4/100
53/53 [==============================] - 1s 11ms/step - loss: 0.2667 - accuracy: 0.8834 - val_loss: 0.2250 - val_accuracy: 0.9011 - lr: 0.0011
Epoch 5/100
53/53 [==============================] - 1s 11ms/step - loss: 0.2623 - accuracy: 0.8918 - val_loss: 0.1936 - val_accuracy: 0.9190 - lr: 0.0011
Epoch 6/100
53/53 [==============================] - 1s 10ms/step - loss: 0.2193 - accuracy: 0.9138 - val_loss: 0.1534 - val_accuracy: 0.9464 - lr: 0.0011
Epoch 7/100
53/53 [==============================] - 1s 10ms/step - loss: 0.2539 - accuracy: 0.9025 - val_loss: 0.2170 - val_accuracy: 0.8832 - lr: 0.0011
Epoch 8/100
53/53 [==============================] - 1s 10ms/step - loss: 0.2130 - accuracy: 0.9132 - val_loss: 0.2705 - val_accuracy: 0.8749 - lr: 0.0011
Epoch 9/100
53/53 [==============================] - 1s 10ms/step - loss: 0.2062 - accuracy: 0.9240 - val_loss: 0.1200 - val_accuracy: 0.9559 - lr: 0.0011
Epoch 10/100
53/53 [==============================] - 1s 12ms/step - loss: 0.1686 - accuracy: 0.9422 - val_loss: 0.1369 - val_accuracy: 0.9583 - lr: 0.0011
Epoch 11/100
53/53 [==============================] - 1s 10ms/step - loss: 0.1810 - accuracy: 0.9338 - val_loss: 0.1488 - val_accuracy: 0.9452 - lr: 0.0011
Epoch 12/100
53/53 [==============================] - 1s 10ms/step - loss: 0.1598 - accuracy: 0.9457 - val_loss: 0.1727 - val_accuracy: 0.9416 - lr: 0.0011
Epoch 13/100
53/53 [==============================] - 1s 10ms/step - loss: 0.1646 - accuracy: 0.9428 - val_loss: 0.1834 - val_accuracy: 0.9225 - lr: 0.0011
Epoch 14/100
53/53 [==============================] - 1s 10ms/step - loss: 0.1255 - accuracy: 0.9609 - val_loss: 0.3798 - val_accuracy: 0.8796 - lr: 0.0011
Epoch 15/100
53/53 [==============================] - 1s 10ms/step - loss: 0.1274 - accuracy: 0.9589 - val_loss: 0.1531 - val_accuracy: 0.9404 - lr: 0.0011
Epoch 16/100
53/53 [==============================] - 1s 10ms/step - loss: 0.1312 - accuracy: 0.9624 - val_loss: 0.2322 - val_accuracy: 0.9106 - lr: 0.0011
Epoch 17/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0928 - accuracy: 0.9756 - val_loss: 0.4950 - val_accuracy: 0.8880 - lr: 0.0011
Epoch 18/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0958 - accuracy: 0.9690 - val_loss: 0.0561 - val_accuracy: 0.9797 - lr: 5.2915e-04
Epoch 19/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0890 - accuracy: 0.9756 - val_loss: 0.1119 - val_accuracy: 0.9607 - lr: 5.2915e-04
Epoch 20/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0826 - accuracy: 0.9770 - val_loss: 0.2304 - val_accuracy: 0.9285 - lr: 5.2915e-04
Epoch 21/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0727 - accuracy: 0.9773 - val_loss: 0.1335 - val_accuracy: 0.9583 - lr: 5.2915e-04
Epoch 22/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0719 - accuracy: 0.9791 - val_loss: 0.2557 - val_accuracy: 0.9237 - lr: 5.2915e-04
Epoch 23/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0684 - accuracy: 0.9818 - val_loss: 0.1433 - val_accuracy: 0.9476 - lr: 5.2915e-04
Epoch 24/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0576 - accuracy: 0.9857 - val_loss: 0.2209 - val_accuracy: 0.9273 - lr: 5.2915e-04
Epoch 25/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0637 - accuracy: 0.9821 - val_loss: 0.0474 - val_accuracy: 0.9857 - lr: 5.2915e-04
Epoch 26/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0506 - accuracy: 0.9851 - val_loss: 0.0447 - val_accuracy: 0.9869 - lr: 5.2915e-04
Epoch 27/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0547 - accuracy: 0.9848 - val_loss: 0.0416 - val_accuracy: 0.9881 - lr: 5.2915e-04
Epoch 28/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0595 - accuracy: 0.9839 - val_loss: 0.0659 - val_accuracy: 0.9785 - lr: 5.2915e-04
Epoch 29/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0651 - accuracy: 0.9818 - val_loss: 0.1009 - val_accuracy: 0.9666 - lr: 5.2915e-04
Epoch 30/100
53/53 [==============================] - 1s 11ms/step - loss: 0.0526 - accuracy: 0.9863 - val_loss: 0.2660 - val_accuracy: 0.9285 - lr: 5.2915e-04
Epoch 31/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0732 - accuracy: 0.9776 - val_loss: 0.2501 - val_accuracy: 0.9297 - lr: 5.2915e-04
Epoch 32/100
53/53 [==============================] - 1s 11ms/step - loss: 0.0581 - accuracy: 0.9830 - val_loss: 0.0695 - val_accuracy: 0.9845 - lr: 5.2915e-04
Epoch 33/100
53/53 [==============================] - 1s 11ms/step - loss: 0.0500 - accuracy: 0.9860 - val_loss: 0.0856 - val_accuracy: 0.9774 - lr: 5.2915e-04
Epoch 34/100
53/53 [==============================] - 1s 11ms/step - loss: 0.0465 - accuracy: 0.9881 - val_loss: 0.0941 - val_accuracy: 0.9666 - lr: 5.2915e-04
Epoch 35/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0484 - accuracy: 0.9854 - val_loss: 0.0426 - val_accuracy: 0.9893 - lr: 5.2915e-04
Epoch 36/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0484 - accuracy: 0.9875 - val_loss: 0.0572 - val_accuracy: 0.9845 - lr: 2.6458e-04
Epoch 37/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0401 - accuracy: 0.9881 - val_loss: 0.0883 - val_accuracy: 0.9726 - lr: 2.6458e-04
Epoch 38/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0465 - accuracy: 0.9881 - val_loss: 0.0465 - val_accuracy: 0.9774 - lr: 2.6458e-04
Epoch 39/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0331 - accuracy: 0.9919 - val_loss: 0.0262 - val_accuracy: 0.9928 - lr: 2.6458e-04
Epoch 40/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0274 - accuracy: 0.9931 - val_loss: 0.0389 - val_accuracy: 0.9857 - lr: 2.6458e-04
Epoch 41/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 0.0223 - val_accuracy: 0.9917 - lr: 2.6458e-04
Epoch 42/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0353 - accuracy: 0.9905 - val_loss: 0.0254 - val_accuracy: 0.9917 - lr: 2.6458e-04
Epoch 43/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0362 - accuracy: 0.9878 - val_loss: 0.0252 - val_accuracy: 0.9928 - lr: 2.6458e-04
Epoch 44/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0425 - accuracy: 0.9869 - val_loss: 0.0532 - val_accuracy: 0.9845 - lr: 2.6458e-04
Epoch 45/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.0725 - val_accuracy: 0.9809 - lr: 2.6458e-04
Epoch 46/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 0.0381 - val_accuracy: 0.9905 - lr: 2.6458e-04
Epoch 47/100
53/53 [==============================] - 1s 11ms/step - loss: 0.0373 - accuracy: 0.9902 - val_loss: 0.0536 - val_accuracy: 0.9833 - lr: 2.6458e-04
Epoch 48/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0299 - accuracy: 0.9934 - val_loss: 0.0504 - val_accuracy: 0.9857 - lr: 2.6458e-04
Epoch 49/100
53/53 [==============================] - 1s 11ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 0.0485 - val_accuracy: 0.9833 - lr: 2.6458e-04
Epoch 50/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0300 - accuracy: 0.9917 - val_loss: 0.0349 - val_accuracy: 0.9905 - lr: 1.3229e-04
Epoch 51/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0298 - accuracy: 0.9925 - val_loss: 0.0569 - val_accuracy: 0.9821 - lr: 1.3229e-04
Epoch 52/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0277 - accuracy: 0.9931 - val_loss: 0.0307 - val_accuracy: 0.9917 - lr: 1.3229e-04
Epoch 53/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0208 - accuracy: 0.9952 - val_loss: 0.0324 - val_accuracy: 0.9881 - lr: 1.3229e-04
Epoch 54/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0217 - accuracy: 0.9940 - val_loss: 0.0452 - val_accuracy: 0.9893 - lr: 1.3229e-04
Epoch 55/100
53/53 [==============================] - 1s 11ms/step - loss: 0.0211 - accuracy: 0.9943 - val_loss: 0.0414 - val_accuracy: 0.9893 - lr: 1.3229e-04
Epoch 56/100
53/53 [==============================] - 1s 10ms/step - loss: 0.0192 - accuracy: 0.9958 - val_loss: 0.0450 - val_accuracy: 0.9893 - lr: 1.3229e-04

Evaluating PSO + CNN + LSTM model performance...

Evaluating PSO + CNN + LSTM Hybrid Model Performance...
57/57 [==============================] - 0s 2ms/step

PSO + CNN + LSTM Hybrid Model - Comprehensive Metrics:
accuracy: 0.9883
precision: 0.9884
recall: 0.9883
f1: 0.9883
r2: 0.9949
far: nan
dr: nan

Classification Report:
               precision    recall  f1-score   support

    DrDoS_DNS       0.99      0.99      0.99       177
   DrDoS_LDAP       0.95      0.98      0.97       180
  DrDoS_MSSQL       0.98      0.94      0.96       180
DrDoS_NetBIOS       1.00      0.99      1.00       180
    DrDoS_NTP       0.98      1.00      0.99       180
   DrDoS_SSDP       0.99      0.98      0.99       180
    DrDoS_UDP       0.99      1.00      1.00       180
          Syn       1.00      0.99      1.00       180
         TFTP       1.00      1.00      1.00       180
       UDPLag       1.00      1.00      1.00       180

     accuracy                           0.99      1797
    macro avg       0.99      0.99      0.99      1797
 weighted avg       0.99      0.99      0.99      1797


PSO + CNN + LSTM model saved successfully

PSO + CNN + LSTM Convergence Summary:
Total iterations: 160
Final best validation loss: 0.3370

======================================================================
PSO + CNN + LSTM Hybrid Model Training Complete!
Model combines:
- Particle Swarm Optimization (PSO) for hyperparameter tuning
- Convolutional Neural Networks (CNN) for spatial feature extraction
- Long Short-Term Memory (LSTM) for temporal pattern recognition
======================================================================